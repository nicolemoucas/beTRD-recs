{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Recommendation on the Players Mock Dataset for Users\n",
    "\n",
    "Implementation of Term Frequency Inverse Document Frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recommenders.models.tfidf.tfidf_utils import TfidfRecommender\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   UUID         PlayerName         PlayerTeam  \\\n",
      "0  b906eb96-4c26-49a9-bc8f-c7989ae5cc67        Luka Modrić        Real Madrid   \n",
      "1  539c9764-bf4f-4a2f-8b62-1489893be273       Sergio Ramos        Real Madrid   \n",
      "2  ecb389db-5a98-4b3d-8662-0d8b7d5c196e         Paul Pogba  Manchester United   \n",
      "3  69c0383f-66ca-4d81-80e3-b3fa0dcd93e0  Cristiano Ronaldo           Al-Nassr   \n",
      "4  24de84b4-b7f6-4cf9-a8bc-e74d40b50f6e  Antoine Griezmann    Atlético Madrid   \n",
      "\n",
      "  PlayerCountry  userId userRiskType UserVote  BetPlaced  BetAmount BetOutcome  \n",
      "0       Croatie      15          Low  Dislike       True      78.66    Pending  \n",
      "1       Espagne      10         High     Like      False       0.00        NaN  \n",
      "2        France      17       Medium     Like      False       0.00        NaN  \n",
      "3      Portugal       1         High  Neutral       True      39.12       Lose  \n",
      "4        France       2       Medium  Dislike      False       0.00        NaN  \n",
      "\n",
      "Number of entries in dataset: 200\n"
     ]
    }
   ],
   "source": [
    "match_df = pd.read_csv('datasets/player_data.csv')\n",
    "\n",
    "print(match_df.head())\n",
    "print('\\nNumber of entries in dataset: ' + str(len(match_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiate the recommender\n",
    "Select one of the following tokenization methods for the model:\n",
    "| tokenization_method | Description                                                                                                                      |\n",
    "|:--------------------|:---------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 'none'              | No tokenization is applied. Each word is considered a token.                                                                     |\n",
    "| 'nltk'              | Simple stemming is applied using NLTK.                                                                                           |\n",
    "| 'bert'              | HuggingFace BERT word tokenization ('bert-base-cased') is applied.                                                               |\n",
    "| 'scibert'           | SciBERT word tokenization ('allenai/scibert_scivocab_cased') is applied.<br>This is recommended for scientific journal articles. |\n",
    "\n",
    "Casing (capitalization) is preserved for [BERT-based tokenization methods](https://huggingface.co/transformers/model_doc/bert.html), but is removed for simple or no tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = TfidfRecommender(id_col='UUID', tokenization_method='scibert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare text for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           al  angleterre   antoine  argentina  atlético       bas   benzema  \\\n",
      "0    0.000000    0.000000  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "1    0.000000    0.000000  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "2    0.000000    0.000000  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "3    0.447214    0.000000  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "4    0.000000    0.000000  0.513927        0.0  0.513927  0.000000  0.000000   \n",
      "..        ...         ...       ...        ...       ...       ...       ...   \n",
      "195  0.000000    0.000000  0.000000        0.0  0.000000  0.000000  0.559823   \n",
      "196  0.000000    0.000000  0.513927        0.0  0.513927  0.000000  0.000000   \n",
      "197  0.000000    0.447214  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "198  0.000000    0.000000  0.000000        0.0  0.000000  0.449709  0.000000   \n",
      "199  0.447214    0.000000  0.000000        0.0  0.000000  0.000000  0.000000   \n",
      "\n",
      "       bruyne  brésil      city  ...  portugal     ramos      real   ronaldo  \\\n",
      "0    0.000000     0.0  0.000000  ...  0.000000  0.000000  0.320409  0.000000   \n",
      "1    0.000000     0.0  0.000000  ...  0.000000  0.542053  0.338673  0.000000   \n",
      "2    0.000000     0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3    0.000000     0.0  0.000000  ...  0.447214  0.000000  0.000000  0.447214   \n",
      "4    0.000000     0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "..        ...     ...       ...  ...       ...       ...       ...       ...   \n",
      "195  0.000000     0.0  0.000000  ...  0.000000  0.000000  0.344235  0.000000   \n",
      "196  0.000000     0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "197  0.000000     0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "198  0.449709     0.0  0.326077  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "199  0.000000     0.0  0.000000  ...  0.447214  0.000000  0.000000  0.447214   \n",
      "\n",
      "     saint  salah    sergio  tottenham    united  verratti  \n",
      "0      0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "1      0.0    0.0  0.542053   0.000000  0.000000       0.0  \n",
      "2      0.0    0.0  0.000000   0.000000  0.510635       0.0  \n",
      "3      0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "4      0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "..     ...    ...       ...        ...       ...       ...  \n",
      "195    0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "196    0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "197    0.0    0.0  0.000000   0.447214  0.000000       0.0  \n",
      "198    0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "199    0.0    0.0  0.000000   0.000000  0.000000       0.0  \n",
      "\n",
      "[200 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine text columns\n",
    "match_df['combined'] = match_df['PlayerName'] + ' ' + match_df['PlayerTeam'] + ' ' + match_df['PlayerCountry']\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "#vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Apply TF-IDF to the combined text data to remove common english words\n",
    "# like \"the\", \"and\", ...\n",
    "#tfidf_matrix = vectorizer.fit_transform(match_df['combined'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for better readability\n",
    "#tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "#print(tfidf_df)\n",
    "df_clean = recommender.clean_dataframe(match_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betrd_kernel",
   "language": "python",
   "name": "betrd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
