{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Single Node on Player Mock dataset\n",
    "\n",
    "Simple Algorithm for Recommendation (SAR) to handle cold item and semi-cold user scenarios. \n",
    "\n",
    "SAR recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users that interacted with one item are also likely to have interacted with the other. A user has an ***affinity*** to an item if they have interacted with it in the past.\n",
    "\n",
    "### Advantages of SAR:\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training, only requiring simple counting to construct matrices used at prediction time. \n",
    "- Fast scoring, only involving multiplication of the similarity matrix with an affinity vector\n",
    "\n",
    "### Notes to use SAR properly:\n",
    "- Since it does not use item or user features, it can be at a disadvantage against algorithms that do.\n",
    "- It's memory-hungry, requiring the creation of an $mxm$ sparse square matrix (where $m$ is the number of items). This can also be a problem for many matrix factorization algorithms.\n",
    "- SAR favors an implicit rating scenario and it does not predict ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.sar import SAR\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    map,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    logloss,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "import logging\n",
    "import numpy as np\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Each row reprensets a single interaction between a user and an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemId  userId  rating            timestamp              playerName  \\\n",
      "0      24     350       2  2020-07-06 07:22:44  Trent Alexander-Arnold   \n",
      "1      22     270       3  2024-05-21 23:33:49  Trent Alexander-Arnold   \n",
      "2       1     168       5  2018-05-18 09:32:21       Cristiano Ronaldo   \n",
      "3       0     425       4  2015-07-14 18:44:49            Lionel Messi   \n",
      "4       0      29       5  2019-02-24 03:26:47            Lionel Messi   \n",
      "\n",
      "  playerTeam playerCountry  \n",
      "0  Liverpool    Angleterre  \n",
      "1    Arsenal    Angleterre  \n",
      "2   Al-Nassr      Portugal  \n",
      "3  Barcelona     Argentina  \n",
      "4  Barcelona     Argentina  \n",
      "\n",
      "Number of entries in dataset: 50000\n"
     ]
    }
   ],
   "source": [
    "match_df = pd.read_csv('datasets/player_data.csv')\n",
    "\n",
    "print(match_df.head())\n",
    "print('\\nNumber of entries in dataset: ' + str(len(match_df)))\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transform data\n",
    "\n",
    "The **rating** column in our dataset is a boolean indicating wheter the user placed a bet or not, so we need to transform it into numerical ratings : 0 and 1.\n",
    "\n",
    "The **timestamp** column needs to be a numeric value, so a new column **timestamp_diff_days** with the difference of days will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       itemId  userId  rating           timestamp              playerName  \\\n",
      "0          24     350     2.0 2020-07-06 07:22:44  Trent Alexander-Arnold   \n",
      "1          22     270     3.0 2024-05-21 23:33:49  Trent Alexander-Arnold   \n",
      "2           1     168     5.0 2018-05-18 09:32:21       Cristiano Ronaldo   \n",
      "3           0     425     4.0 2015-07-14 18:44:49            Lionel Messi   \n",
      "4           0      29     5.0 2019-02-24 03:26:47            Lionel Messi   \n",
      "...       ...     ...     ...                 ...                     ...   \n",
      "49995      17      84     2.0 2012-07-26 06:30:43              Toni Kroos   \n",
      "49996      45     399     1.0 2016-03-16 18:37:04          Erling Haaland   \n",
      "49997       8     247     1.0 2017-04-18 11:16:41         Kevin De Bruyne   \n",
      "49998      38     445     4.0 2021-11-14 02:37:08             Luka ModriÄ‡   \n",
      "49999      24     213     4.0 2024-03-03 19:03:02  Trent Alexander-Arnold   \n",
      "\n",
      "              playerTeam playerCountry  timestamp_seconds  \n",
      "0              Liverpool    Angleterre         1594020164  \n",
      "1                Arsenal    Angleterre         1716334429  \n",
      "2               Al-Nassr      Portugal         1526635941  \n",
      "3              Barcelona     Argentina         1436899489  \n",
      "4              Barcelona     Argentina         1550978807  \n",
      "...                  ...           ...                ...  \n",
      "49995      Bayern Munich     Allemagne         1343284243  \n",
      "49996             Monaco        Norway         1458153424  \n",
      "49997    Manchester City      Pays-Bas         1492514201  \n",
      "49998  Tottenham Hotspur       Croatie         1636857428  \n",
      "49999          Liverpool    Angleterre         1709492582  \n",
      "\n",
      "[50000 rows x 8 columns]\n",
      "itemId                        int64\n",
      "userId                        int64\n",
      "rating                      float32\n",
      "timestamp            datetime64[ns]\n",
      "playerName                   object\n",
      "playerTeam                   object\n",
      "playerCountry                object\n",
      "timestamp_seconds             int64\n",
      "dtype: object\n",
      "\n",
      "null lines:  0\n"
     ]
    }
   ],
   "source": [
    "#print(match_df.head())\n",
    "epoch_time = dt.datetime(1970, 1, 1)\n",
    "\n",
    "# Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "match_df['rating'] = match_df['rating'].astype(np.float32)\n",
    "\n",
    "match_df['timestamp'] = pd.to_datetime(match_df['timestamp'])\n",
    "match_df['timestamp_seconds'] = match_df['timestamp'].astype('int64') // 10**9\n",
    "\n",
    "print(match_df)\n",
    "\n",
    "print(match_df.dtypes)\n",
    "\n",
    "# Check number of null lines, should be 0\n",
    "print(\"\\nnull lines: \", match_df['timestamp_seconds'].isna().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split data using python random splitter\n",
    "\n",
    "Split dataset into train and test dataset to evaluate algorithm performance.\n",
    "All users that are in th test set must also exist in the training set, so we use `python_stratified_split`. \n",
    "The function holds out a percentage (25% here) of items from each user, but ensures all users are in both `train` and `test` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(match_df, ratio=0.75, col_user=\"userId\", col_item=\"itemId\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 37505\n",
      "Unique Users: 500\n",
      "Unique Items: 51\n",
      "\n",
      "Test:\n",
      "Total Ratings: 12495\n",
      "Unique Users: 500\n",
      "Unique Items: 51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train['userId'].unique()),\n",
    "    train_items=len(train['itemId'].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test['userId'].unique()),\n",
    "    test_items=len(test['itemId'].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the SAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Instantiate the SAR algorithm and set the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SAR(\n",
    "    col_user=\"userId\",\n",
    "    col_item=\"itemId\",\n",
    "    col_rating=\"rating\",\n",
    "    col_timestamp=\"timestamp_seconds\",\n",
    "    similarity_type=\"jaccard\", \n",
    "    time_decay_coefficient=30, \n",
    "    timedecay_formula=True,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train the SAR model on the training data, and get the top-k recommendations for the testing data\n",
    "\n",
    "SAR creates an item-to-item **co-occurence matrix** (number of times two items are together for a given user), then we compute an **item similarity matrix** by rescaling the cooccurences by given metric.\n",
    "\n",
    "We also compute an **affinity matrix** to capture the strength of the relationship between each user and each item.\n",
    "\n",
    "We get the **recommendations** by multiplying the affinity matrix and the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 18:59:59,259 INFO     Collecting user affinity matrix\n",
      "2025-01-28 18:59:59,261 INFO     Calculating time-decayed affinities\n",
      "2025-01-28 18:59:59,266 INFO     Creating index columns\n",
      "2025-01-28 18:59:59,276 INFO     Calculating normalization factors\n",
      "2025-01-28 18:59:59,280 INFO     Building user affinity sparse matrix\n",
      "2025-01-28 18:59:59,282 INFO     Calculating item co-occurrence\n",
      "2025-01-28 18:59:59,284 INFO     Calculating item similarity\n",
      "2025-01-28 18:59:59,284 INFO     Using jaccard based similarity\n",
      "2025-01-28 18:59:59,285 INFO     Done training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 0.02944191699998555 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Training finished in {} seconds.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 18:59:59,290 INFO     Calculating recommendation scores\n",
      "2025-01-28 18:59:59,292 INFO     Removing seen items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction finished in 0.006701333000023624 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    top_k = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "print(\"Prediction finished in {} seconds.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.046925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.045363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.044808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.044477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.044472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>500</td>\n",
       "      <td>43</td>\n",
       "      <td>0.002435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>500</td>\n",
       "      <td>13</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>500</td>\n",
       "      <td>35</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4741 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  itemId  prediction\n",
       "0          1      23    0.046925\n",
       "1          1      11    0.045363\n",
       "2          1      31    0.044808\n",
       "3          1      36    0.044477\n",
       "4          1      46    0.044472\n",
       "...      ...     ...         ...\n",
       "4993     500      43    0.002435\n",
       "4994     500       1    0.002433\n",
       "4995     500      13    0.002401\n",
       "4996     500      35    0.002395\n",
       "4997     500      32    0.002355\n",
       "\n",
       "[4741 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluate SAR performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:438: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/recommenders/evaluation/python_evaluation.py:439: FutureWarning: Passing a dictionary to SeriesGroupBy.agg is deprecated and will raise in a future version of pandas. Pass a list of aggregations instead.\n",
      "  rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n"
     ]
    }
   ],
   "source": [
    "# Ranking metrics\n",
    "eval_map = map(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\", k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\", k=TOP_K)\n",
    "eval_precision = precision_at_k(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\", k=TOP_K)\n",
    "eval_recall = recall_at_k(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\", k=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating metrics\n",
    "eval_rmse = rmse(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\")\n",
    "eval_mae = mae(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\")\n",
    "eval_rsquared = rsquared(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\")\n",
    "eval_exp_var = exp_var(test, top_k, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivity_threshold = 2\n",
    "test_bin = test.copy()\n",
    "test_bin[\"rating\"] = binarize(test_bin[\"rating\"], positivity_threshold)\n",
    "\n",
    "top_k_prob = top_k.copy()\n",
    "top_k_prob[\"prediction\"] = minmax_scale(top_k_prob[\"prediction\"].astype(float))\n",
    "\n",
    "eval_logloss = logloss(\n",
    "    test_bin, top_k_prob, col_user=\"userId\", col_item=\"itemId\", col_rating=\"rating\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t\n",
      "Top K:\t10\n",
      "MAP:\t0.136550\n",
      "NDCG:\t0.728474\n",
      "Precision@K:\t0.471600\n",
      "Recall@K:\t0.189971\n",
      "RMSE:\t3.243994\n",
      "MAE:\t2.921707\n",
      "R2:\t-4.317032\n",
      "Exp var:\t-0.004000\n",
      "Logloss:\t1.720861\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\t\",\n",
    "      \"Top K:\\t%d\" % TOP_K,\n",
    "      \"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall,\n",
    "      \"RMSE:\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t%f\" % eval_mae,\n",
    "      \"R2:\\t%f\" % eval_rsquared,\n",
    "      \"Exp var:\\t%f\" % eval_exp_var,\n",
    "      \"Logloss:\\t%f\" % eval_logloss,\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 18:59:59,620 INFO     Calculating recommendation scores\n",
      "2025-01-28 18:59:59,621 INFO     Removing seen items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>playerName</th>\n",
       "      <th>playerTeam</th>\n",
       "      <th>playerCountry</th>\n",
       "      <th>timestamp_seconds</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>272</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-07-13 18:36:23</td>\n",
       "      <td>Toni Kroos</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Allemagne</td>\n",
       "      <td>1342204583</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>272</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-03-04 15:33:39</td>\n",
       "      <td>Bruno Fernandes</td>\n",
       "      <td>Real Betis</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>1393947219</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-02-16 15:42:00</td>\n",
       "      <td>Luka ModriÄ‡</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Croatie</td>\n",
       "      <td>1361029320</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-10-11 19:28:14</td>\n",
       "      <td>Mohamed Salah</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Maroc</td>\n",
       "      <td>1476214094</td>\n",
       "      <td>0.124271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-05-17 09:19:56</td>\n",
       "      <td>Erling Haaland</td>\n",
       "      <td>Red Bull Salzburg</td>\n",
       "      <td>Norway</td>\n",
       "      <td>1621243196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>272</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-01-27 09:21:06</td>\n",
       "      <td>Trent Alexander-Arnold</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Angleterre</td>\n",
       "      <td>1327656066</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>272</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-07-12 18:45:48</td>\n",
       "      <td>Luka ModriÄ‡</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>Croatie</td>\n",
       "      <td>1626115548</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>272</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-01 13:42:14</td>\n",
       "      <td>Sergio Busquets</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Espagne</td>\n",
       "      <td>1596289334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>272</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-09-10 20:12:58</td>\n",
       "      <td>Karim Benzema</td>\n",
       "      <td>Al-Ittihad</td>\n",
       "      <td>France</td>\n",
       "      <td>1441915978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-07-11 05:00:22</td>\n",
       "      <td>Sergio Ramos</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Espagne</td>\n",
       "      <td>1689051622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemId  userId  rating           timestamp              playerName  \\\n",
       "0      17     272     5.0 2012-07-13 18:36:23              Toni Kroos   \n",
       "1      14     272     5.0 2014-03-04 15:33:39         Bruno Fernandes   \n",
       "2       5     272     4.0 2013-02-16 15:42:00             Luka ModriÄ‡   \n",
       "3      11     272     4.0 2016-10-11 19:28:14           Mohamed Salah   \n",
       "4      40     272     4.0 2021-05-17 09:19:56          Erling Haaland   \n",
       "5      22     272     3.0 2012-01-27 09:21:06  Trent Alexander-Arnold   \n",
       "6      38     272     3.0 2021-07-12 18:45:48             Luka ModriÄ‡   \n",
       "7      16     272     3.0 2020-08-01 13:42:14         Sergio Busquets   \n",
       "8       6     272     3.0 2015-09-10 20:12:58           Karim Benzema   \n",
       "9       7     272     3.0 2023-07-11 05:00:22            Sergio Ramos   \n",
       "\n",
       "          playerTeam playerCountry  timestamp_seconds  prediction  \n",
       "0      Bayern Munich     Allemagne         1342204583         NaN  \n",
       "1         Real Betis      Portugal         1393947219         NaN  \n",
       "2        Real Madrid       Croatie         1361029320         NaN  \n",
       "3          Liverpool         Maroc         1476214094    0.124271  \n",
       "4  Red Bull Salzburg        Norway         1621243196         NaN  \n",
       "5            Arsenal    Angleterre         1327656066         NaN  \n",
       "6  Tottenham Hotspur       Croatie         1626115548         NaN  \n",
       "7          Barcelona       Espagne         1596289334         NaN  \n",
       "8         Al-Ittihad        France         1441915978         NaN  \n",
       "9        Real Madrid       Espagne         1689051622         NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the results for a specific user\n",
    "user_id = 272\n",
    "\n",
    "ground_truth = test[test[\"userId\"] == user_id].sort_values(\n",
    "    by=\"rating\", ascending=False\n",
    ")[:TOP_K]\n",
    "prediction = model.recommend_k_items(\n",
    "    pd.DataFrame(dict(userId=[user_id])), remove_seen=True\n",
    ")\n",
    "df = pd.merge(ground_truth, prediction, on=[\"userId\", \"itemId\"], how=\"left\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.13655048779326887,
        "encoder": "json",
        "name": "map"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "map"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.7284736570091731,
        "encoder": "json",
        "name": "ndcg"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "ndcg"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.4716,
        "encoder": "json",
        "name": "precision"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "precision"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.18997059112229095,
        "encoder": "json",
        "name": "recall"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "recall"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.02944191699998555,
        "encoder": "json",
        "name": "train_time"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "train_time"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "application/notebook_utils.json+json": {
        "data": 0.006701333000023624,
        "encoder": "json",
        "name": "test_time"
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "notebook_utils": {
        "data": true,
        "display": false,
        "name": "test_time"
       },
       "raw": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Record results for tests - ignore this cell\n",
    "store_metadata(\"map\", eval_map)\n",
    "store_metadata(\"ndcg\", eval_ndcg)\n",
    "store_metadata(\"precision\", eval_precision)\n",
    "store_metadata(\"recall\", eval_recall)\n",
    "store_metadata(\"train_time\", train_time.interval)\n",
    "store_metadata(\"test_time\", test_time.interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betrd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
