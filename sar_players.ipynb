{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAR Single Node on Player Mock dataset\n",
    "\n",
    "Simple Algorithm for Recommendation (SAR) to handle cold item and semi-cold user scenarios. \n",
    "\n",
    "SAR recommends items that are most ***similar*** to the ones that the user already has an existing ***affinity*** for. Two items are ***similar*** if the users that interacted with one item are also likely to have interacted with the other. A user has an ***affinity*** to an item if they have interacted with it in the past.\n",
    "\n",
    "### Advantages of SAR:\n",
    "- High accuracy for an easy to train and deploy algorithm\n",
    "- Fast training, only requiring simple counting to construct matrices used at prediction time. \n",
    "- Fast scoring, only involving multiplication of the similarity matrix with an affinity vector\n",
    "\n",
    "### Notes to use SAR properly:\n",
    "- Since it does not use item or user features, it can be at a disadvantage against algorithms that do.\n",
    "- It's memory-hungry, requiring the creation of an $mxm$ sparse square matrix (where $m$ is the number of items). This can also be a problem for many matrix factorization algorithms.\n",
    "- SAR favors an implicit rating scenario and it does not predict ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.sar import SAR\n",
    "from recommenders.utils.timer import Timer\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Each row reprensets a single interaction between a user and an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 itemId     playerName           playerTeam  \\\n",
      "0  c4493a2b-8c67-4345-a052-ddd8988be736  Karim Benzema          Real Madrid   \n",
      "1  46f3b28a-d110-4f9a-8f85-f953cf283d9d         Neymar  Paris Saint Germain   \n",
      "2  76b0dca2-0634-4df2-8904-3195b4bc4257         Neymar  Paris Saint Germain   \n",
      "3  d2906d5f-c345-4811-a8df-3b7c2a937f6f  Mohamed Salah            Liverpool   \n",
      "4  5d724afc-6f4c-4d7b-9b94-c3c5add68c88  Kylian Mbappé          Real Madrid   \n",
      "\n",
      "  playerCountry  userId userRiskType  betPlaced  betAmount  \\\n",
      "0        France       8       Medium      False       0.00   \n",
      "1        Brésil      11       Medium      False       0.00   \n",
      "2        Brésil      11       Medium       True      90.12   \n",
      "3         Maroc       1         High      False       0.00   \n",
      "4       Espagne       7         High      False       0.00   \n",
      "\n",
      "             timestamp  \n",
      "0  2022-12-04 00:00:00  \n",
      "1  2023-06-16 00:00:00  \n",
      "2  2023-11-13 00:00:00  \n",
      "3  2024-06-01 00:00:00  \n",
      "4  2024-11-30 00:00:00  \n",
      "\n",
      "Number of entries in dataset: 200\n"
     ]
    }
   ],
   "source": [
    "match_df = pd.read_csv('datasets/player_data.csv')\n",
    "\n",
    "print(match_df.head())\n",
    "print('\\nNumber of entries in dataset: ' + str(len(match_df)))\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transform data\n",
    "\n",
    "The **rating** column in our dataset is a boolean indicating wheter the user placed a bet or not, so we need to transform it into numerical ratings : 0 and 1.\n",
    "\n",
    "The **timestamp** column needs to be a numeric value, so a new column **timestamp_diff_days** with the difference of days will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 itemId     playerName           playerTeam  \\\n",
      "0  c4493a2b-8c67-4345-a052-ddd8988be736  Karim Benzema          Real Madrid   \n",
      "1  46f3b28a-d110-4f9a-8f85-f953cf283d9d         Neymar  Paris Saint Germain   \n",
      "2  76b0dca2-0634-4df2-8904-3195b4bc4257         Neymar  Paris Saint Germain   \n",
      "3  d2906d5f-c345-4811-a8df-3b7c2a937f6f  Mohamed Salah            Liverpool   \n",
      "4  5d724afc-6f4c-4d7b-9b94-c3c5add68c88  Kylian Mbappé          Real Madrid   \n",
      "\n",
      "  playerCountry  userId userRiskType  betPlaced  betAmount  \\\n",
      "0        France       8       Medium      False       0.00   \n",
      "1        Brésil      11       Medium      False       0.00   \n",
      "2        Brésil      11       Medium       True      90.12   \n",
      "3         Maroc       1         High      False       0.00   \n",
      "4       Espagne       7         High      False       0.00   \n",
      "\n",
      "             timestamp  \n",
      "0  2022-12-04 00:00:00  \n",
      "1  2023-06-16 00:00:00  \n",
      "2  2023-11-13 00:00:00  \n",
      "3  2024-06-01 00:00:00  \n",
      "4  2024-11-30 00:00:00  \n",
      "                                 itemId     playerName           playerTeam  \\\n",
      "0  c4493a2b-8c67-4345-a052-ddd8988be736  Karim Benzema          Real Madrid   \n",
      "1  46f3b28a-d110-4f9a-8f85-f953cf283d9d         Neymar  Paris Saint Germain   \n",
      "2  76b0dca2-0634-4df2-8904-3195b4bc4257         Neymar  Paris Saint Germain   \n",
      "3  d2906d5f-c345-4811-a8df-3b7c2a937f6f  Mohamed Salah            Liverpool   \n",
      "4  5d724afc-6f4c-4d7b-9b94-c3c5add68c88  Kylian Mbappé          Real Madrid   \n",
      "\n",
      "  playerCountry  userId userRiskType  betPlaced  betAmount  timestamp  \\\n",
      "0        France       8       Medium          0       0.00 2022-12-04   \n",
      "1        Brésil      11       Medium          0       0.00 2023-06-16   \n",
      "2        Brésil      11       Medium          1      90.12 2023-11-13   \n",
      "3         Maroc       1         High          0       0.00 2024-06-01   \n",
      "4       Espagne       7         High          0       0.00 2024-11-30   \n",
      "\n",
      "   timestamp_diff_secs  \n",
      "0         1.670112e+09  \n",
      "1         1.686874e+09  \n",
      "2         1.699834e+09  \n",
      "3         1.717200e+09  \n",
      "4         1.732925e+09  \n",
      "itemId                         object\n",
      "playerName                     object\n",
      "playerTeam                     object\n",
      "playerCountry                  object\n",
      "userId                          int64\n",
      "userRiskType                   object\n",
      "betPlaced                       int64\n",
      "betAmount                     float64\n",
      "timestamp              datetime64[ns]\n",
      "timestamp_diff_secs           float64\n",
      "dtype: object\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(match_df.head())\n",
    "\n",
    "match_df['betPlaced'] = match_df['betPlaced'].astype(int)\n",
    "match_df['timestamp'] = pd.to_datetime(match_df['timestamp'])\n",
    "match_df['timestamp_diff_secs'] = match_df['timestamp'].apply(lambda x : x.timestamp())\n",
    "\n",
    "\n",
    "print(match_df.head())\n",
    "\n",
    "print(match_df.dtypes)\n",
    "\n",
    "# Check number of null lines, should be 0\n",
    "print(match_df['timestamp_diff_secs'].isna().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split data using python random splitter\n",
    "\n",
    "Split dataset into train and test dataset to evaluate algorithm performance.\n",
    "All users that are in th test set must also exist in the training set, so we use `python_stratified_split`. \n",
    "The function holds out a percentage (25% here) of items from each user, but ensures all users are in both `train` and `test` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_stratified_split(match_df, ratio=0.75, col_user=\"userId\", col_item=\"itemId\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 149\n",
      "Unique Users: 18\n",
      "Unique Items: 149\n",
      "\n",
      "Test:\n",
      "Total Ratings: 51\n",
      "Unique Users: 18\n",
      "Unique Items: 51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train['userId'].unique()),\n",
    "    train_items=len(train['itemId'].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test['userId'].unique()),\n",
    "    test_items=len(test['itemId'].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the SAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Instantiate the SAR algorithm and set the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SAR(\n",
    "    col_user=\"userId\",\n",
    "    col_item=\"itemId\",\n",
    "    col_rating=\"betPlaced\",\n",
    "    col_timestamp=\"timestamp_diff_secs\",\n",
    "    similarity_type=\"jaccard\", \n",
    "    time_decay_coefficient=30, \n",
    "    timedecay_formula=False,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train the SAR model on the training data, and get the top-k recommendations for the testing data\n",
    "\n",
    "SAR creates an item-to-item **co-occurence matrix** (number of times two items are together for a given user), then we compute an **item similarity matrix** by rescaling the cooccurences by given metric.\n",
    "\n",
    "We also compute an **affinity matrix** to capture the strength of the relationship between each user and each item.\n",
    "\n",
    "We get the **recommendations** by multiplying the affinity matrix and the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 11:22:22,073 INFO     Collecting user affinity matrix\n",
      "2024-12-04 11:22:22,073 INFO     Creating index columns\n",
      "2024-12-04 11:22:22,075 INFO     Calculating normalization factors\n",
      "2024-12-04 11:22:22,075 INFO     Building user affinity sparse matrix\n",
      "2024-12-04 11:22:22,075 INFO     Calculating item co-occurrence\n",
      "2024-12-04 11:22:22,076 INFO     Calculating item similarity\n",
      "2024-12-04 11:22:22,077 INFO     Using jaccard based similarity\n",
      "2024-12-04 11:22:22,077 INFO     Done training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 0.005976916999998139 seconds.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(train)\n",
    "\n",
    "print(\"Training finished in {} seconds.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 11:22:22,081 INFO     Calculating recommendation scores\n",
      "2024-12-04 11:22:22,082 INFO     Removing seen items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.003283291000002464 seconds for prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolecastromoucheron/miniconda3/envs/betrd_env/lib/python3.9/site-packages/scipy/sparse/_data.py:140: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self._with_data(self.data * other)\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    top_k = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>e6b2d561-bbbc-4a60-a526-a6a72d7cbb6d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b3c5fe9f-797d-4331-b866-04468f37d084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2dde7a9b-e40d-4e76-b183-89c78464b0bb</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6515bec6-8e6a-423c-9fbc-bf99771d0d32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5d724afc-6f4c-4d7b-9b94-c3c5add68c88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>17</td>\n",
       "      <td>d671b837-4797-45b8-9193-305b0d6dd961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>18</td>\n",
       "      <td>73d4af48-5f53-4711-a724-f578a9af0aa8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>18</td>\n",
       "      <td>5d724afc-6f4c-4d7b-9b94-c3c5add68c88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>18</td>\n",
       "      <td>6515bec6-8e6a-423c-9fbc-bf99771d0d32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>18</td>\n",
       "      <td>10095b92-9c9d-4872-93bc-5364e2723833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId                                itemId  prediction\n",
       "0         1  e6b2d561-bbbc-4a60-a526-a6a72d7cbb6d         0.0\n",
       "1         1  b3c5fe9f-797d-4331-b866-04468f37d084         0.0\n",
       "2         1  2dde7a9b-e40d-4e76-b183-89c78464b0bb         0.0\n",
       "3         1  6515bec6-8e6a-423c-9fbc-bf99771d0d32         0.0\n",
       "4         1  5d724afc-6f4c-4d7b-9b94-c3c5add68c88         0.0\n",
       "..      ...                                   ...         ...\n",
       "166      17  d671b837-4797-45b8-9193-305b0d6dd961         0.0\n",
       "170      18  73d4af48-5f53-4711-a724-f578a9af0aa8         0.0\n",
       "171      18  5d724afc-6f4c-4d7b-9b94-c3c5add68c88         0.0\n",
       "172      18  6515bec6-8e6a-423c-9fbc-bf99771d0d32         0.0\n",
       "173      18  10095b92-9c9d-4872-93bc-5364e2723833         0.0\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betrd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
